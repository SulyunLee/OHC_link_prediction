'''
Author: Sulyun Lee
This script generates the text-similarity-based features for the input dataset with the baseline features.
Text-similarity-based features: the cosine similarity between the LDA vector with 30 topic distributions
'''

#----------------Import libraries-------------------
import pandas as pd
import numpy as np
from tqdm import tqdm
import networkx as nx
from sklearn.metrics.pairwise import cosine_similarity
from generate_LDA import *
#--------------------------------------------------

def make_textsim_feature(row, user_lda_thisweek, channel):

    instance = eval(row['pair'])

    # slice the dataframe that contains the posts corresponding to the user, channel, and week
    node1_posts = user_lda_thisweek.loc[(user_lda_thisweek['Type'] == channel) & (user_lda_thisweek['source'] == instance[0]),]
    node2_posts = user_lda_thisweek.loc[(user_lda_thisweek['Type'] == channel) & (user_lda_thisweek['source'] == instance[1]),]

    # if either of nodes do not have any posts posted during this week, in this channel, return 0
    if node1_posts.shape[0] == 0 or node2_posts.shape[0] == 0:
        return 0
    else:
        # compute the average topic distribution for two users
        node1_avg_distr = np.array(node1_posts['topic_distr'].values.tolist()).sum(axis=0) / node1_posts.shape[0]
        node2_avg_distr = np.array(node2_posts['topic_distr'].values.tolist()).sum(axis=0) / node2_posts.shape[0]

        # compute the cosine similarity
        sim = cosine_similarity(node1_avg_distr.reshape((1,-1)), node2_avg_distr.reshape((1,-1)))
        sim = float(sim)

        return sim



if __name__ == "__main__":
    #--------------Initialize parameters------------------
    # Input datafile with baseline features
    data_dir = 'data/proposed_model/'

    start_week = 50
    end_week = 101
    #----------------------------------------------------

    # load the topic distribution dataframe generated by other python script
    user_lda_df = generate_lda_df(start_week, end_week)


    for i in range(1,end_week - start_week - 1):
    # for i in range(1):

        input_train_df = pd.read_csv(data_dir + 'bax_week{}_train.csv'.format(start_week+i))
        input_test_df = pd.read_csv(data_dir + 'bax_week{}_test.csv'.format(start_week+i))

        print('Making week{} train and test data...'.format(start_week+i))
        user_lda_thisweek = user_lda_df.loc[user_lda_df['Week'] == start_week+i,]

        tqdm.pandas()
        input_train_df['BC_Textsim'] = input_train_df.progress_apply(make_textsim_feature, args=[user_lda_thisweek, 'BC'], axis=1)
        input_train_df['GD_Textsim'] = input_train_df.progress_apply(make_textsim_feature, args=[user_lda_thisweek, 'GD'], axis=1)
        input_train_df['MB_Textsim'] = input_train_df.progress_apply(make_textsim_feature, args=[user_lda_thisweek, 'MB'], axis=1)

        user_lda_nextweek = user_lda_df.loc[user_lda_df['Week'] == start_week+i+1,]
        input_test_df['BC_Textsim'] = input_test_df.progress_apply(make_textsim_feature, args=[user_lda_nextweek, 'BC'], axis=1)
        input_test_df['GD_Textsim'] = input_test_df.progress_apply(make_textsim_feature, args=[user_lda_nextweek, 'GD'], axis=1)
        input_test_df['MB_Textsim'] = input_test_df.progress_apply(make_textsim_feature, args=[user_lda_nextweek, 'MB'], axis=1)

        input_train_df = input_train_df[['pair','BC_PA','BC_AA','BC_JC','BC_Textsim','GD_PA','GD_AA','GD_JC','GD_Textsim','MB_PA','MB_AA','MB_JC','MB_Textsim','PM_PA','PM_AA','PM_JC','label']]
        input_test_df = input_test_df[['pair','BC_PA','BC_AA','BC_JC','BC_Textsim','GD_PA','GD_AA','GD_JC','GD_Textsim','MB_PA','MB_AA','MB_JC','MB_Textsim','PM_PA','PM_AA','PM_JC','label']]

        print('Writing dataset to csv file...')
        input_train_df.to_csv('data/proposed_textsim/bax_week{}_train.csv'.format(start_week+i), index=False)
        input_test_df.to_csv('data/proposed_textsim/bax_week{}_test.csv'.format(start_week+i), index=False)

